{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🎯 **Problem Statement**\n",
        "\n",
        " **Create chains that perform the following tasks:**\n",
        "\n",
        "1. 🟢 **Identifies the sentiment** of a given text.\n",
        "2. 🔵 **Based on the sentiment, generates a follow-up question:**\n",
        "   - If the sentiment is **positive**, the follow-up question will be related to what made it positive.\n",
        "   - If the sentiment is **negative**, the follow-up question will be about what made it negative.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ceAYSOTSl8R5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hints and Instructions"
      ],
      "metadata": {
        "id": "Hjxv_QMCmHw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Install Required Libraries**:\n",
        "   - Begin by installing the necessary Python libraries using pip, which is the Python package installer. Each `!pip install` command installs a different package:\n",
        "     - `langchain` - A library for building applications using large language models.\n",
        "     - `openai` - The official Python library for interacting with OpenAI’s APIs, including GPT models.\n",
        "     - `cohere` - A Python library for integrating Cohere's language models into applications.\n",
        "     - `langchain_community` - An additional set of tools or extensions for `langchain` that might be community-driven or experimental.\n",
        "\n",
        "\n",
        "\n",
        "2. **Importing Modules**:\n",
        "   - After installing the packages, import the necessary modules from the `langchain` library along with other Python standard libraries:\n",
        "     - From `langchain`, import `LLMChain`, `SequentialChain`, `Prompt`, `OpenAI`, `Cohere`, and `PromptTemplate`. These are classes and methods used to set up and utilize language model chains and prompts effectively.\n",
        "     - Import the `os` module from Python’s standard library, which will be used to manage environment variables.\n",
        "\n",
        "\n",
        "\n",
        "3. **Set Environment Variables**:\n",
        "   - Set up the environment variable for the Cohere API key. This is crucial for authenticating API requests to Cohere. Replace `\"Your Cohere Key\"` with the actual API key provided to you by Cohere.\n",
        "   - The `os.environ` dictionary in Python is used to set environment variables. Here, you're setting the `'COHERE_API_KEY'` environment variable which the `cohere` library will use to authenticate your requests.\n",
        "\n",
        "\n",
        "Ensure you replace `\"Your Cohere Key\"` with your actual Cohere API key before running the code. Also, make sure you have the appropriate permissions and environment (like Jupyter notebook or a Python script) where system commands like `!pip install` are allowed to execute."
      ],
      "metadata": {
        "id": "PidCB-sCreuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install cohere\n"
      ],
      "metadata": {
        "id": "G73WuTwCsjTY",
        "outputId": "f52c171b-5cd0-47e9-ad90-d06f04409033",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.19)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.15 (from langchain)\n",
            "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.23.1-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Downloading langchain_community-0.3.9-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.9-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.19\n",
            "    Uninstalling langchain-core-0.3.19:\n",
            "      Successfully uninstalled langchain-core-0.3.19\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.7\n",
            "    Uninstalling langchain-0.3.7:\n",
            "      Successfully uninstalled langchain-0.3.7\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.9 langchain-community-0.3.9 langchain-core-0.3.21 marshmallow-3.23.1 mypy-extensions-1.0.0 pydantic-settings-2.6.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.13.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.27.2)\n",
            "Requirement already satisfied: httpx-sse==0.4.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (1.26.4)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.9.2)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.23.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.10/dist-packages (from cohere) (0.20.3)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.21.2->cohere) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<1,>=0.15->cohere) (0.26.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.2.2)\n",
            "Downloading cohere-5.13.3-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: types-requests, parameterized, fastavro, cohere\n",
            "Successfully installed cohere-5.13.3 fastavro-1.9.7 parameterized-0.9.0 types-requests-2.32.0.20241016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code here\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.llms import Cohere\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "import os"
      ],
      "metadata": {
        "id": "yXgUkFbhmZG-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['COHERE_API_KEY'] = userdata.get('COHERE_API_KEY')"
      ],
      "metadata": {
        "id": "36rgTkFXnfm3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uiDOw8AH7pQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain 1: Define a chain to identify the sentiment of the input text"
      ],
      "metadata": {
        "id": "wUXDYuvso4vH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Initialize the Language Model (LLM)**:\n",
        "   - First, instantiate the Cohere language model. This object, `llm`, will be used to process inputs through the language model's API.\n",
        "   - Ensure that the Cohere library is installed and that you have set up necessary API keys or other configurations as required.\n",
        "\n",
        "2. **Create a Prompt Template**:\n",
        "   - Define a `PromptTemplate` which specifies how the input should be formatted when sent to the language model.\n",
        "   - `input_variables`: This is a list of variables that you expect to dynamically change in your prompt template. In this case, it is [\"text\"], which will be replaced by actual text you want to analyze.\n",
        "   - `template`: This string lays out the text structure sent to the model. It instructs the model to analyze the sentiment of the input text and respond with either 'Positive' or 'Negative'. It incorporates `{text}` as a placeholder that will be replaced with actual text at runtime.\n",
        "\n",
        "\n",
        "3. **Setup the Sentiment Analysis Chain**:\n",
        "   - Create an `LLMChain` object, which uses the `llm` you initialized and the `prompt` you defined.\n",
        "   - `prompt`: This is set to the `sentiment_analysis_prompt` object.\n",
        "   - `output_key`: This parameter specifies which part of the response to focus on or extract. Since the prompt instructs the model to end responses with \"Sentiment:\", this key helps in extracting the actual sentiment value ('Positive' or 'Negative') from the response.\n",
        "\n",
        "\n",
        "4. **Invoke the Chain and Print the Result**:\n",
        "   - Use the `invoke` method on the `sentiment_analysis_chain` object, providing a string of text that you wish to analyze. This is where the sentiment analysis actually happens.\n",
        "   - Print the extracted sentiment. The result will be accessed using the `output_key` specified earlier (\"sentiment\"), which should give either 'Positive' or 'Negative' based on the text analysis.\n"
      ],
      "metadata": {
        "id": "vAkkBNcqrv5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your Code here\n",
        "\n",
        "\n",
        "\n",
        "llm=Cohere()\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "take the below text as input. respond 'positive' or 'negative' depending on the sentiment of the text\n",
        "text is given here {input_text}\n",
        "\"\"\"\n",
        "\n",
        "sentiment_analysis_prompt=PromptTemplate(input_variables=[\"input_text\"],template=template)\n",
        "\n",
        "sentiment_analysis_chain=LLMChain(llm=llm,prompt=sentiment_analysis_prompt,output_key=\"sentiment\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vgq8_UuHsgVY",
        "outputId": "bae72500-6963-48ed-e358-7ede680d0027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-13d8ea1efc6a>:5: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import Cohere``.\n",
            "  llm=Cohere()\n",
            "<ipython-input-4-13d8ea1efc6a>:15: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  sentiment_analysis_chain=LLMChain(llm=llm,prompt=sentiment_analysis_prompt,output_key=\"sentiment\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=sentiment_analysis_chain.invoke({'input_text':'the product quality is very bad'})\n",
        "print(result['sentiment'])"
      ],
      "metadata": {
        "id": "Mgt1HnejnyLa",
        "outputId": "63920629-45c0-4bf0-c246-e813a371ec3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Negative. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=Cohere()\n",
        "\n",
        "template=\"\"\"\n",
        "Take the sentiment of the text as input and generate a followup question based on the sentiment.\n",
        "Sentiment is given below here\n",
        "\"\"\"\n",
        "\n",
        "prompt=PromptTemplate(\n",
        "    input_variables=[\"input_text\"],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "\n",
        "chain1=LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt,\n",
        "    output_key=\"output1\"\n",
        "    )\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mxYP5xTDtx_c"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "result=chain1.invoke({'input_text':'the product quality is very bad'})\n",
        "print(result['output1'])\n"
      ],
      "metadata": {
        "id": "TKyFTlXyt5L5",
        "outputId": "70f1b1d2-3848-4ad3-b00e-6659a55f9f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The sentiment in the text is positive about passengers using cars for transportation. Would you like me to help you craft a marketing pitch for a delivery service that is focusing on car transportation? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CHAIN 2\n",
        "\n",
        "\n",
        "llm=Cohere()\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "\n",
        "take the setinemt of the text as input and generate a followup......\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt2=PromptTemplate(\n",
        "    input_variables=['output1'],\n",
        "    template=template\n",
        ")\n",
        "\n",
        "\n",
        "chain2=LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt2,\n",
        "    output_key=\"output2\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SP-oLJX5LX1R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result=chain2.invoke({'output1':'positive'})\n",
        "print(result['output2'])"
      ],
      "metadata": {
        "id": "-XpJ8dm4LX3_",
        "outputId": "e700c2c6-c81f-410e-a539-8f3453acc081",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I'm sorry, could you please clarify what you'd like me to do? I can perform a variety of tasks such as answering questions, providing information, and assisting you with writing drafts. If you provide me with a piece of text, I can attempt to identify the key themes and generate a follow-up text related to it. \n",
            "\n",
            "Let me know if you have any specific requests or if you would like me to suggest a few options for follow-up text topics. \n",
            "\n",
            "I'm here to help! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DoHEE6dYLX6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#combine both chain\n",
        "#sequential chain\n",
        "\n",
        "\n",
        "final_chain=SequentialChain(\n",
        "    chains=[chain1,chain2],\n",
        "    input_variables=['input_text'],\n",
        "    output_variables=['output1','output2']\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NAQIHKX5LX9D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=\"i had a great time at the park todya . the weather was perfect and the park was great\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TObhIehfLYAm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "result=final_chain.invoke({'input_text':input_text})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "gedi7k7RNZHU",
        "outputId": "157b9f21-696b-40b4-9f6f-1c48b9df655d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_text': 'i had a great time at the park todya . the weather was perfect and the park was great', 'output1': ' The sentiment of the provided text has been identified as neutral. \\n\\nAs a follow-up question, I would like to know more about the context surrounding the sentiment expressed. Could you provide additional details or specific aspects of the situation that may have influenced the sentiment? ', 'output2': \" I'm sorry, can you please clarify what you'd like me to do? \\n\\nIf you want me to summarize a provided text, please input the text so I can create a summary from it.  Otherwise, if you'd like me to generate a follow up question based on the previous text, I'd be happy to do so. Just let me know what you'd like me to do, and I'll be happy to assist! \"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chain 2: Define a chain to generate a follow-up question based on the sentiment"
      ],
      "metadata": {
        "id": "E9VPuq8jo_iU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Initialize the Language Model (LLM)**:\n",
        "   - First, instantiate the Cohere language model. This object, `llm`, will be used to process inputs through the language model's API.\n",
        "   - Make sure that the Cohere library is installed and that you have configured it properly with necessary API keys.\n",
        "\n",
        "2. **Define a Prompt Template**:\n",
        "   - Create a `PromptTemplate` which specifies how to format the input when sending it to the language model.\n",
        "   - `input_variables`: List the variables that will dynamically change in the prompt template. Here, \"sentiment\" is the variable that will be replaced with either 'Positive' or 'Negative'.\n",
        "   - `template`: This string outlines the text structure to send to the model. It provides instructions for generating a follow-up question based on the sentiment ('Positive' or 'Negative'). This template uses conditional language to specify different questions for different sentiments.\n",
        "\n",
        "\n",
        "\n",
        "3. **Setup the Follow-Up Question Chain**:\n",
        "   - Create an `LLMChain` object using the `llm` and `prompt` you defined.\n",
        "   - `prompt`: This is set to the `follow_up_question_prompt` object.\n",
        "   - `output_key`: This parameter specifies which part of the response to extract. In this case, the model is instructed to generate a follow-up question, so the `output_key` is \"follow_up_question\".\n",
        "\n",
        "\n",
        "\n",
        "4. **Invoke the Chain and Print the Result**:\n",
        "   - Use the `invoke` method on the `follow_up_question_chain` object, providing an input that specifies the sentiment (either \"Positive\" or \"Negative\"). This is where the follow-up question generation happens.\n",
        "   - Print the follow-up question extracted. The result will be accessed using the `output_key` specified earlier (\"follow_up_question\").\n"
      ],
      "metadata": {
        "id": "dplYJ8jVszbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code here"
      ],
      "metadata": {
        "id": "dNBZj9Vys8GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uaLyuetpo_Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sq4czblBt0Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9890Z2r7t3bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine both chains into a SequentialChain"
      ],
      "metadata": {
        "id": "VBVdXzCMqILm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Define the SequentialChain**:\n",
        "   - **`SequentialChain`**: This is a special type of chain in `langchain` that allows multiple chains to be executed in sequence. Each chain’s output can be used as input for the subsequent chain in the sequence.\n",
        "   - **`chains`**: List the chains that will be run in sequence. Here, `sentiment_analysis_chain` analyzes the sentiment of the text, and `follow_up_question_chain` generates a follow-up question based on the detected sentiment.\n",
        "   - **`input_variables`**: Define the variables that the first chain in the sequence expects. In this case, `[\"text\"]` indicates that the initial input will be plain text.\n",
        "   - **`output_variables`**: Specify the variables that will be output after the last chain has run. Here, `[\"sentiment\", \"follow_up_question\"]` are expected as outputs from the entire sequence.\n",
        "\n",
        "\n",
        "2. **Prepare the Input Text**:\n",
        "   - Define a variable `input_text` containing the text you want to analyze. This example uses a simple statement about having a great time at the park, which is suitable for sentiment analysis.\n",
        "\n",
        "\n",
        "3. **Invoke the SequentialChain**:\n",
        "   - Call the `invoke` method on the `sentiment_chain`, passing a dictionary with the `text` key set to `input_text`. This dictionary matches the `input_variables` defined in the `SequentialChain`.\n",
        "   - The `invoke` method will process the text through both chains sequentially: first analyzing sentiment and then generating a follow-up question.\n",
        "\n",
        "\n",
        "4. **Print the Results**:\n",
        "   - Extract and print the sentiment and follow-up question from the result. The keys used for extraction (`\"sentiment\"` and `\"follow_up_question\"`) match those defined in the `output_variables` of the `SequentialChain`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "837i7JbJs-sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your Code here"
      ],
      "metadata": {
        "id": "4TZcTwMatTPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5eyvGtWmBVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWPM8EyLmTl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mlgCL1C5t2Hi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}