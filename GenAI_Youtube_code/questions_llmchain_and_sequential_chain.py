# -*- coding: utf-8 -*-
"""Questions_LLMChain_and_Sequential_Chain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fnpYleTCLJlO3CzFisDHjljEZBhhMUgq

# ðŸŽ¯ **Problem Statement**

 **Create chains that perform the following tasks:**

1. ðŸŸ¢ **Identifies the sentiment** of a given text.
2. ðŸ”µ **Based on the sentiment, generates a follow-up question:**
   - If the sentiment is **positive**, the follow-up question will be related to what made it positive.
   - If the sentiment is **negative**, the follow-up question will be about what made it negative.

---

#Hints and Instructions

1. **Install Required Libraries**:
   - Begin by installing the necessary Python libraries using pip, which is the Python package installer. Each `!pip install` command installs a different package:
     - `langchain` - A library for building applications using large language models.
     - `openai` - The official Python library for interacting with OpenAIâ€™s APIs, including GPT models.
     - `cohere` - A Python library for integrating Cohere's language models into applications.
     - `langchain_community` - An additional set of tools or extensions for `langchain` that might be community-driven or experimental.



2. **Importing Modules**:
   - After installing the packages, import the necessary modules from the `langchain` library along with other Python standard libraries:
     - From `langchain`, import `LLMChain`, `SequentialChain`, `Prompt`, `OpenAI`, `Cohere`, and `PromptTemplate`. These are classes and methods used to set up and utilize language model chains and prompts effectively.
     - Import the `os` module from Pythonâ€™s standard library, which will be used to manage environment variables.



3. **Set Environment Variables**:
   - Set up the environment variable for the Cohere API key. This is crucial for authenticating API requests to Cohere. Replace `"Your Cohere Key"` with the actual API key provided to you by Cohere.
   - The `os.environ` dictionary in Python is used to set environment variables. Here, you're setting the `'COHERE_API_KEY'` environment variable which the `cohere` library will use to authenticate your requests.


Ensure you replace `"Your Cohere Key"` with your actual Cohere API key before running the code. Also, make sure you have the appropriate permissions and environment (like Jupyter notebook or a Python script) where system commands like `!pip install` are allowed to execute.
"""

!pip install langchain langchain-community
!pip install langchain
!pip install openai
!pip install cohere

#Write your code here
from langchain.llms import OpenAI
from langchain.llms import Cohere
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.chains import SequentialChain
import os

import os
from google.colab import userdata
os.environ['COHERE_API_KEY'] = userdata.get('COHERE_API_KEY')



"""## Chain 1: Define a chain to identify the sentiment of the input text

1. **Initialize the Language Model (LLM)**:
   - First, instantiate the Cohere language model. This object, `llm`, will be used to process inputs through the language model's API.
   - Ensure that the Cohere library is installed and that you have set up necessary API keys or other configurations as required.

2. **Create a Prompt Template**:
   - Define a `PromptTemplate` which specifies how the input should be formatted when sent to the language model.
   - `input_variables`: This is a list of variables that you expect to dynamically change in your prompt template. In this case, it is ["text"], which will be replaced by actual text you want to analyze.
   - `template`: This string lays out the text structure sent to the model. It instructs the model to analyze the sentiment of the input text and respond with either 'Positive' or 'Negative'. It incorporates `{text}` as a placeholder that will be replaced with actual text at runtime.


3. **Setup the Sentiment Analysis Chain**:
   - Create an `LLMChain` object, which uses the `llm` you initialized and the `prompt` you defined.
   - `prompt`: This is set to the `sentiment_analysis_prompt` object.
   - `output_key`: This parameter specifies which part of the response to focus on or extract. Since the prompt instructs the model to end responses with "Sentiment:", this key helps in extracting the actual sentiment value ('Positive' or 'Negative') from the response.


4. **Invoke the Chain and Print the Result**:
   - Use the `invoke` method on the `sentiment_analysis_chain` object, providing a string of text that you wish to analyze. This is where the sentiment analysis actually happens.
   - Print the extracted sentiment. The result will be accessed using the `output_key` specified earlier ("sentiment"), which should give either 'Positive' or 'Negative' based on the text analysis.
"""

#Write your Code here



llm=Cohere()


template="""
take the below text as input. respond 'positive' or 'negative' depending on the sentiment of the text
text is given here {input_text}
"""

sentiment_analysis_prompt=PromptTemplate(input_variables=["input_text"],template=template)

sentiment_analysis_chain=LLMChain(llm=llm,prompt=sentiment_analysis_prompt,output_key="sentiment")

result=sentiment_analysis_chain.invoke({'input_text':'the product quality is very bad'})
print(result['sentiment'])

llm=Cohere()

template="""
Take the sentiment of the text as input and generate a followup question based on the sentiment.
Sentiment is given below here
"""

prompt=PromptTemplate(
    input_variables=["input_text"],
    template=template
)


chain1=LLMChain(
    llm=llm,
    prompt=prompt,
    output_key="output1"
    )

result=chain1.invoke({'input_text':'the product quality is very bad'})
print(result['output1'])

#CHAIN 2


llm=Cohere()


template="""

take the setinemt of the text as input and generate a followup......
"""


prompt2=PromptTemplate(
    input_variables=['output1'],
    template=template
)


chain2=LLMChain(
    llm=llm,
    prompt=prompt2,
    output_key="output2"
)

result=chain2.invoke({'output1':'positive'})
print(result['output2'])



#combine both chain
#sequential chain


final_chain=SequentialChain(
    chains=[chain1,chain2],
    input_variables=['input_text'],
    output_variables=['output1','output2']
)

input_text="i had a great time at the park todya . the weather was perfect and the park was great"

result=final_chain.invoke({'input_text':input_text})
print(result)

"""## Chain 2: Define a chain to generate a follow-up question based on the sentiment

1. **Initialize the Language Model (LLM)**:
   - First, instantiate the Cohere language model. This object, `llm`, will be used to process inputs through the language model's API.
   - Make sure that the Cohere library is installed and that you have configured it properly with necessary API keys.

2. **Define a Prompt Template**:
   - Create a `PromptTemplate` which specifies how to format the input when sending it to the language model.
   - `input_variables`: List the variables that will dynamically change in the prompt template. Here, "sentiment" is the variable that will be replaced with either 'Positive' or 'Negative'.
   - `template`: This string outlines the text structure to send to the model. It provides instructions for generating a follow-up question based on the sentiment ('Positive' or 'Negative'). This template uses conditional language to specify different questions for different sentiments.



3. **Setup the Follow-Up Question Chain**:
   - Create an `LLMChain` object using the `llm` and `prompt` you defined.
   - `prompt`: This is set to the `follow_up_question_prompt` object.
   - `output_key`: This parameter specifies which part of the response to extract. In this case, the model is instructed to generate a follow-up question, so the `output_key` is "follow_up_question".



4. **Invoke the Chain and Print the Result**:
   - Use the `invoke` method on the `follow_up_question_chain` object, providing an input that specifies the sentiment (either "Positive" or "Negative"). This is where the follow-up question generation happens.
   - Print the follow-up question extracted. The result will be accessed using the `output_key` specified earlier ("follow_up_question").
"""

#Write your code here







"""## Combine both chains into a SequentialChain

1. **Define the SequentialChain**:
   - **`SequentialChain`**: This is a special type of chain in `langchain` that allows multiple chains to be executed in sequence. Each chainâ€™s output can be used as input for the subsequent chain in the sequence.
   - **`chains`**: List the chains that will be run in sequence. Here, `sentiment_analysis_chain` analyzes the sentiment of the text, and `follow_up_question_chain` generates a follow-up question based on the detected sentiment.
   - **`input_variables`**: Define the variables that the first chain in the sequence expects. In this case, `["text"]` indicates that the initial input will be plain text.
   - **`output_variables`**: Specify the variables that will be output after the last chain has run. Here, `["sentiment", "follow_up_question"]` are expected as outputs from the entire sequence.


2. **Prepare the Input Text**:
   - Define a variable `input_text` containing the text you want to analyze. This example uses a simple statement about having a great time at the park, which is suitable for sentiment analysis.


3. **Invoke the SequentialChain**:
   - Call the `invoke` method on the `sentiment_chain`, passing a dictionary with the `text` key set to `input_text`. This dictionary matches the `input_variables` defined in the `SequentialChain`.
   - The `invoke` method will process the text through both chains sequentially: first analyzing sentiment and then generating a follow-up question.


4. **Print the Results**:
   - Extract and print the sentiment and follow-up question from the result. The keys used for extraction (`"sentiment"` and `"follow_up_question"`) match those defined in the `output_variables` of the `SequentialChain`.
"""

#Write your Code here





